#!/data/data/com.termux/files/usr/bin/python
import argparse
import re
from concurrent.futures import ProcessPoolExecutor
from pathlib import Path

# Regex patterns for the two states
NORMAL_IMPORT = r"^import re\b"
REGEX_IMPORT = r"^import regex as re\b"


def update_file(file_path, reverse=False):
    """Processes a single file to swap the import statements."""
    try:
        lines = file_path.read_text(encoding="utf-8").splitlines(keepends=True)
        new_lines = []
        changed = False

        # Define search and replace based on direction
        search_pat = REGEX_IMPORT if reverse else NORMAL_IMPORT
        replacement = "import re" if reverse else "import regex as re"

        for line in lines:
            # Only attempt replacement if we haven't hit the main body of the code
            # (Crude check: stop if line starts with a char that isn't import/from/whitespace/#)
            if not changed and re.match(search_pat, line):
                new_lines.append(
                    re.sub(
                        search_pat,
                        replacement,
                        line,
                    )
                )
                changed = True
            else:
                new_lines.append(line)

        if changed:
            file_path.write_text(
                "".join(new_lines),
                encoding="utf-8",
            )
            return f"Updated: {file_path}"
        return None

    except Exception as e:
        return f"Error processing {file_path}: {e}"


def main():
    parser = argparse.ArgumentParser(description="Recursively swap 'import re' with 'import regex as re'")
    parser.add_argument(
        "-r",
        "--reverse",
        action="store_true",
        help="Reverse the replacement (regex as re -> re)",
    )
    args = parser.parse_args()

    # Gather all .py files recursively
    py_files = list(Path(".").rglob("*.py"))

    print(f"Scanning {len(py_files)} files...")

    # Use ProcessPoolExecutor for parallel processing
    with ProcessPoolExecutor() as executor:
        # Map the update function to all found files
        results = list(
            executor.map(
                update_file,
                py_files,
                [args.reverse] * len(py_files),
            )
        )

    # Filter and print results
    updates = [r for r in results if r]
    for msg in updates:
        print(msg)

    print(f"\nTask complete. Files modified: {len(updates)}")


if __name__ == "__main__":
    main()
